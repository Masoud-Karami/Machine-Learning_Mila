{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "#tp2 INF8953CE",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYFCuzaBRXbW"
      },
      "source": [
        "**# Masoud Karami**      **2050716**\n",
        "\n",
        "\n",
        "[INF8953CE(Fall 2020) : Machine Learning](http://sarathchandar.in/teaching/ml/fall2020/)\n",
        "[Assignment #2](https://drive.google.com/file/d/10TncIjTPBt0kkIEm8XlFdDcJrd4Bopse/view) Due on : Oct 26, 10:00 pm\n",
        "\n",
        "* You have to submit the pdf copy of the report on gradescope before the deadline. If you\n",
        "handwrite your solutions, you need to scan the pages, merge them to a single pdf file and\n",
        "submit. Mark page 1 for outline items $Late\\ Submission$ and $Verbosity$.\n",
        "\n",
        "* When asked to report the parameters, save the corresponding parameters in a text file\n",
        "(.txt) with the following template for the name: \n",
        "`Assignment1 <Matricule> <section> <sub-question > <sub-sub-question>`. Submit all the text files and codes compressed\n",
        "to a single file `<your-matricule>.zip` on Moodle.\n",
        "\n",
        "$Note:$ gradescope doesn’t accept `.zip`.\n",
        "\n",
        "* Be precise with your explanations in the report. Unnecessary verbosity will be penalized.\n",
        "* You are free to use libraries with general utilities, such as `matplotlib`, `numpy` and `scipy` for\n",
        "`python`. However, you should implement the algorithms yourself, which means **you should not** use pre-existing implementations of the algorithms as found in `SciKit learn`,\n",
        "Tensorflow, etc.!\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05707W5FSKUz"
      },
      "source": [
        "# Linear Classification and Nearest Neighbor Classification\n",
        "\n",
        "> **1.** You will use a synthetic data set for the classification task that you’ll generate yourself.\n",
        "Generate two classes with $20$ features each. Each class is given by a multivariate Gaussian\n",
        "distribution, with both classes sharing the same covariance matrix. You are provided\n",
        "with the mean vectors ($DS1-m0$ for mean vector of negative class and $DS1-m1$ for mean\n",
        "vector of positive class) and the covariance matrix ($DS1-cov$). Generate $2000$ examples\n",
        "for each class, and label the data to be positive if they came from the Gaussian with\n",
        "mean m1 and negative if they came from the Gaussian with mean $m0$. Randomly pick\n",
        "(without replacement) $20%$ of each class (i.e., $400$ data points per class) as test set, $20%$\n",
        "of each class (i.e., $400$ data points per class) as validation set and train the classifiers\n",
        "on the remaining $60%$ data. When you report performance results, it should be on the\n",
        "test set. Call this dataset as $DS1$, and submit it with your code. Follow the instructions\n",
        "from Assignment 1 for data submission format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl5h-JK636Qq"
      },
      "source": [
        "# import sys\n",
        "# import os\n",
        "\n",
        "\n",
        "# filelist = [ f for f in os.listdir('/content/') if f.endswith(\".txt\") or f.endswith(\".csv\")]\n",
        "# for f in filelist:\n",
        "#     os.remove(os.path.join('/content/', f))\n",
        "##sys.modules[__name__].__dict__.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdnpTazzuI7_"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "# import csv, operator\n",
        "import os\n",
        "import sys\n",
        "import scipy.stats as stats\n",
        "import pylab as pl\n",
        "\n",
        "\n",
        "\n",
        "data_path = '/content'\n",
        "ds1_m0 = np.loadtxt(data_path +'/DS1_m_0.txt', delimiter = ',', usecols = range(20))\n",
        "# print('DS1_m_0', ds1_m0)\n",
        "\n",
        "ds1_m1 = np.loadtxt(data_path +'/DS1_m_1.txt', delimiter = ',', usecols = range(20))\n",
        "# print('DS1_m_1', ds1_m1)\n",
        "\n",
        "ds1_cov = np.loadtxt(data_path + '/DS1_Cov.txt', delimiter = ',', usecols = range(20))\n",
        "# print('DS1_Cov is a', type(ds1_cov), ds1_cov.shape)\n",
        "\n",
        "# plt.plot(ds1_cov)\n",
        "# plt.title('DS1_Cov')\n",
        "# fig = plt.gcf()\n",
        "# fig.set_size_inches(10, 6)\n",
        "# plt.show()\n",
        "\n",
        "minus = np.random.multivariate_normal(ds1_m0, ds1_cov, 2000)\n",
        "plus = np.random.multivariate_normal(ds1_m1, ds1_cov, 2000)\n",
        "# fit = stats.norm.pdf(minus, np.mean(minus), np.std(minus))\n",
        "\n",
        "\n",
        "# print('negative class is a', type(minus), minus.shape)\n",
        "# print('positive class is a', type(plus), plus.shape)\n",
        "\n",
        "minus = np.insert(minus, 20, 0, axis = 1)\n",
        "plus = np.insert(plus, 20, 1, axis = 1)\n",
        "\n",
        "# plt.hist(minus, label='negative')\n",
        "# plt.ylim([0,1000])\n",
        "# plt.legend(loc = 'upper right')\n",
        "# plt.show()\n",
        "\n",
        "# plt.hist(plus, label='positive')\n",
        "# plt.legend(loc = 'upper right')\n",
        "# plt.ylim([0,1000])\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "train_minus = minus[800:]\n",
        "valid_minus = minus[400:800]\n",
        "test_minus = minus[:400]\n",
        "\n",
        "train_plus = plus[800:]\n",
        "valid_plus = plus[400:800]\n",
        "test_plus = plus[:400]\n",
        "\n",
        "ds1_train = np.append(train_minus , train_plus, axis=0)\n",
        "ds1_valid = np.append(valid_minus , valid_plus, axis=0)\n",
        "ds1_test = np.append(test_minus, test_plus, axis=0)\n",
        "\n",
        "np.random.shuffle(ds1_train)\n",
        "np.random.shuffle(ds1_valid)\n",
        "np.random.shuffle(ds1_test)\n",
        "\n",
        "DS1 = np.append(np.append(ds1_train, ds1_test, axis=0), ds1_valid, axis=0)\n",
        "\n",
        "# print('train set is a', type(ds1_train), ds1_train.shape, 'like', ds1_train[0:1,0:4], '...')\n",
        "# print('validation set is a', type(ds1_valid), ds1_valid.shape, 'like', ds1_valid[0:1,0:4], '...')\n",
        "# print('test set is a', type(ds1_test), ds1_test.shape, 'like', ds1_test[0:1,0:4], '...')\n",
        "\n",
        "# type(ds1_m0)\n",
        "# print(ds1_m0)\n",
        "\n",
        "np.savetxt('DS1_train.csv', ds1_train, delimiter=',')\n",
        "np.savetxt('DS1_valid.csv', ds1_valid, delimiter=',')\n",
        "np.savetxt('DS1_test.csv', ds1_test, delimiter=',')\n",
        "np.savetxt('DS1.csv', DS1, delimiter=',')\n",
        "# plt.plot(ds1_train)\n",
        "# plt.polar(ds1_train)\n",
        "# plt.plot(DS1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6C9u1IXTIrC"
      },
      "source": [
        "> **2.** We first consider the $GDA$ model as seen in class: given the class variable, the data are\n",
        "assumed to be Gaussians with different means for different classes but with the same\n",
        "covariance matrix. This model can formally be specified as follows:\n",
        "\n",
        "\\begin{align*}\n",
        " Y \\sim Bernoulli(\\pi), && X|Y=j\\sim \\mathcal{N}(\\mu_j, \\Sigma).\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpUdyM4fWRwo"
      },
      "source": [
        ">>**2.1** Estimate the parameters of the $GDA$ model using the maximum likelihood approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG1TxwAuWdMu"
      },
      "source": [
        ">>>**2.1.a** For $DS1$, report the best fit accuracy, precision, recall and $F-$measure achieved by the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q37Zi9n5pDC8"
      },
      "source": [
        "print('Question #2.1.a', '\\n')\n",
        "\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "minus_num = 0\n",
        "plus_num = 0\n",
        "mu_0 = np.zeros(20)\n",
        "mu_1= np.zeros(20)\n",
        "s_0 = 0\n",
        "s_1 = 0\n",
        "n = len(ds1_train)\n",
        "for row in ds1_train:\n",
        "  if row[20] == 0:\n",
        "    minus_num += 1\n",
        "    mu_0 += row[:20]\n",
        "  else:\n",
        "    plus_num += 1\n",
        "    mu_1 += row[:20]\n",
        "\n",
        "\n",
        "p_0 = minus_num/(minus_num + plus_num)\n",
        "p_1 = plus_num/(minus_num + plus_num)\n",
        "mu_0 /= minus_num\n",
        "mu_1/= plus_num\n",
        "\n",
        "\n",
        "#---------------------------------------------------------\n",
        "\n",
        "def cov_matrix(data_set):\n",
        "  s_0 = 0\n",
        "  s_1 = 0\n",
        "  n = len(data_set)\n",
        "  for row in data_set:\n",
        "    if row[20]==0:\n",
        "      last = np.array(row[:20])\n",
        "      last -= mu_0\n",
        "      last = np.reshape(last,(20,1))       \n",
        "      s_0 += last.dot(last.T)\n",
        "\n",
        "  s_0  /= minus_num\n",
        "  for row in data_set:\n",
        "    if row[20]==1:\n",
        "      last = np.array(row[:20])\n",
        "      last -= mu_1\n",
        "      last = np.reshape(last,(20,1))    \n",
        "      s_1 += last.dot(last.T)\n",
        "\n",
        "  s_1 /= plus_num\n",
        "  return p_0*s_0 + p_1*s_1\n",
        "#---------------------------------------------------------\n",
        "\n",
        "def gaussian_disc(data_set):\n",
        "  cov_temp = np.linalg.inv(cov_matrix(data_set))\n",
        "  w_1 = cov_temp.dot(mu_0 - mu_1)\n",
        "  w_0 = -0.5*(mu_0.T).dot(cov_temp).dot(mu_0) + 0.5*(mu_1.T).dot(cov_temp).dot(mu_1) + np.log(minus_num/plus_num)\n",
        "  print(\"w_1 =\", '\\n',w_1)\n",
        "  print(\"w_0 =\", '\\n', w_0)\n",
        "  return w_0, w_1\n",
        "#---------------------------------------------------------\n",
        "\n",
        "def activation(x, b, a):\n",
        "  discriminant = b + a.dot(x)\n",
        "  return 1/(1 + np.exp(-discriminant))\n",
        "#---------------------------------------------------------\n",
        "\n",
        "def GDA_params(data_set, b, a):\n",
        "  true_positives = 0\n",
        "  true_negatives = 0\n",
        "  false_positives = 0\n",
        "  false_negatives = 0\n",
        "  for row in data_set:\n",
        "    if row[-1] == 0:\n",
        "      if activation(row[:-1], b, a) >= 0.5:\n",
        "        true_negatives += 1\n",
        "      else:\n",
        "        false_positives += 1\n",
        "    else:\n",
        "      if activation(row[:-1], b, a) < 0.5:\n",
        "        true_positives += 1\n",
        "      else:\n",
        "        false_negatives += 1\n",
        "  # print(tabulate([['true_positives =', true_positives], ['false_positives =', false_positives],\n",
        "  #                ['true_negatives =', true_negatives], ['false_negatives =', false_negatives]]))\n",
        "  precision = true_positives/(true_positives + false_positives)\n",
        "  recall = true_positives/(true_positives + false_negatives)\n",
        "  accuracy = (true_positives + true_negatives)/(true_positives + false_negatives + true_negatives + false_positives)\n",
        "  F_1 = 2*precision*recall/(precision + recall)\n",
        "\n",
        "  # print and table setting\n",
        "  # print(tabulate([['Accuracy =', accuracy], ['Precision =', precision],\n",
        "  #                ['Recall =', recall], ['F_1 measure =', F_1]]))\n",
        "  # matrix = np.array([[true_positives, false_positives],\n",
        "  #                          [false_negatives, true_negatives]])\n",
        "  # fig, ax = plt.subplots()\n",
        "  # im = ax.imshow(matrix)\n",
        "  # actual_value = [\"Actual Positive\", \"Actual Negative\"]\n",
        "  # predicted_value = [\"predicted Positive\", \"predicted Negative\"]\n",
        "  # ax.set_xticks(np.arange(len(predicted_value)))\n",
        "  # ax.set_yticks(np.arange(len(actual_value)))\n",
        "  # ax.set_xticklabels(predicted_value)\n",
        "  # ax.set_yticklabels(actual_value)\n",
        "  # plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "  # for i in range(len(actual_value)):\n",
        "  #   for j in range(len(predicted_value)):\n",
        "  #     text = ax.text(j, i, matrix[i, j],ha=\"center\", va=\"center\", color=\"r\")\n",
        "  # fig.tight_layout()\n",
        "  # fig.show()\n",
        "  np.savetxt(\"#2_1_a DS1 parameters.txt\", ['DS1 parameters generated by GDA are: \\n w_1 = {} \\n'.format(w_1),\n",
        "                                           'and \\n w_0 = {} \\n.'.format(w_0),\n",
        "                                           'Other related values are:\\n',\n",
        "                                           'true_positives = {}'.format(true_positives),\n",
        "                                           'true_negatives = {}'.format(true_negatives), \n",
        "                                           'false_positives = {}'.format(false_positives),\n",
        "                                           'false_negatives = {} \\n'.format(false_negatives),\n",
        "                                           'F_1 measure = {}'.format(F_1),\n",
        "                                           'Accuracy = {}'.format(accuracy),\n",
        "                                           'Precision = {}'.format(precision),\n",
        "                                           'Recall = {}'.format(recall)], fmt='%s')\n",
        "\n",
        "\n",
        "w_0, w_1 = gaussian_disc(ds1_train)\n",
        "#------------------------------------------------------------------------------\n",
        "# parameters for test set\n",
        "if __name__ == \"__main__\":\n",
        "  GDA_params(ds1_test, w_0, w_1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mb5CZ_RWtK-"
      },
      "source": [
        ">>>**2.1.b** Report the coefficients learnt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVRL9PNPn-hx"
      },
      "source": [
        "print('Question #2.1.b', '\\n')\n",
        "\n",
        "def gaussian_disc(data_set):\n",
        "  cov_temp = np.linalg.inv(cov_matrix(data_set))\n",
        "  w_1 = cov_temp.dot(mu_0 - mu_1)\n",
        "  w_0 = -0.5*(mu_0.T).dot(cov_temp).dot(mu_0) + 0.5*(mu_1.T).dot(cov_temp).dot(mu_1) + np.log(minus_num/plus_num)\n",
        "  print('Coefficients are: \\n', \"w_1 =\", '\\n',w_1)\n",
        "  print(\"w_0 =\", '\\n', w_0)\n",
        "  return w_0, w_1\n",
        "\n",
        "\n",
        "w_0, w_1 = gaussian_disc(ds1_train)\n",
        "np.savetxt(\"#2_1_b coefficients learnt.txt\", ['Coefficients are: \\n w_0 = {},'.format(w_0), \n",
        "                                              ' and \\n w_1 = {}.'.format(w_1)], fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiYaitIEWwbw"
      },
      "source": [
        ">**3** For $DS1$, use $k-NN$ to learn a classifier. Repeat the experiment for different values of $k$\n",
        "and report the performance for each value. We will compare this non-linear classifier to\n",
        "the linear approach, and find out how powerful linear classifiers can be.\n",
        "\n",
        ">>**3.a** Does this classifier performs better than $GDA$ or worse? Are there particular values\n",
        "of $k$ which perform better? Why does this happen ? Use $F1-$Measure for model\n",
        "selection.\n",
        "\n",
        ">>**3.b** Report the best fit accuracy, precision, recall and $f-$measure achieved by this classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqdGKCtGDqyy"
      },
      "source": [
        "def KNN(x, k, data_set):\n",
        "  n_neighbours = []\n",
        "  n = len(data_set)\n",
        "  distance = []\n",
        "  in_or_out = 0\n",
        "  for pow,row in enumerate(data_set):\n",
        "    distance = np.linalg.norm(x - row[:20])\n",
        "    if len(n_neighbours) < k:\n",
        "      n_neighbours.append([distance , pow])\n",
        "    else:\n",
        "      n_neighbours = sorted(n_neighbours, key = lambda x: x[0])\n",
        "      if distance < n_neighbours[k-1][0]:\n",
        "        n_neighbours[-1] = [distance,pow]\n",
        "  for neighbour in n_neighbours:\n",
        "    in_or_out += data_set[neighbour[1]][-1]\n",
        "  in_or_out /=k\n",
        "  return in_or_out\n",
        "\n",
        "\n",
        "def KNN_GDA_params(k, data_set):\n",
        "  true_positives = 0\n",
        "  true_negatives = 0\n",
        "  false_positives = 0\n",
        "  false_negatives = 0\n",
        "  for row in data_set:\n",
        "    if row[-1] == 0:\n",
        "      if KNN(row[:-1],k, data_set) <= 0.5:\n",
        "        true_negatives += 1\n",
        "      else:\n",
        "        false_positives += 1\n",
        "    else:\n",
        "      if KNN(row[:-1],k, data_set) > 0.5:\n",
        "        true_positives += 1\n",
        "      else:\n",
        "        false_negatives += 1\n",
        "  # print(tabulate([['KNN-GDA for k=', k], ['true_positives =', true_positives], ['false_positives =', false_positives],\n",
        "  #               ['true_negatives =', true_negatives], ['false_negatives =', false_negatives]]))\n",
        "  precision = true_positives/(true_positives + false_positives)\n",
        "  recall = true_positives/(true_positives + false_negatives)\n",
        "  accuracy = (true_positives + true_negatives)/(true_positives + false_negatives + true_negatives + false_positives)\n",
        "  F_1 = 2*precision*recall/(precision + recall)\n",
        "  params = [precision, recall, accuracy, F_1, k]\n",
        "  # # print and table setting\n",
        "  # '''\n",
        "  # https://matplotlib.org/3.3.2/gallery/images_contours_and_fields/\n",
        "  # image_annotated_heatmap.html#sphx-glr-gallery-images-contours-and-fields-image-annotated-heatmap-py\n",
        "  # '''\n",
        "  # print(tabulate([['k =', k], ['Accuracy =', accuracy], ['Precision =', precision],\n",
        "  #               ['Recall =', recall], ['F_1 measure =', F_1]]))\n",
        "  # matrix = np.array([[true_positives, false_positives],\n",
        "  #                         [false_negatives, true_negatives]])\n",
        "  # fig, ax = plt.subplots()\n",
        "  # im = ax.imshow(matrix)\n",
        "  # actual_value = [\"Actual Positive\", \"Actual Negative\"]\n",
        "  # predicted_value = [\"predicted Positive\", \"predicted Negative\"]\n",
        "  # ax.set_xticks(np.arange(len(predicted_value)))\n",
        "  # ax.set_yticks(np.arange(len(actual_value)))\n",
        "  # ax.set_xticklabels(predicted_value)\n",
        "  # ax.set_yticklabels(actual_value)\n",
        "  # ax.set_title(\"KNN-GDA for k = {}\".format(k))\n",
        "  # plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "  # for i in range(len(actual_value)):\n",
        "  #   for j in range(len(predicted_value)):\n",
        "  #     text = ax.text(j, i, matrix[i, j],ha=\"center\", va=\"center\", color=\"w\")\n",
        "  # fig.tight_layout()\n",
        "  # plt.show()\n",
        "  with open('#3_a KNN-GDA parameters.txt','a') as f:\n",
        "    np.savetxt(f, ['KNN_GDA for k={}'.format(k), \n",
        "                                                'true_positives = {}'.format(k, true_positives),\n",
        "                                                'true_negatives = {}'.format(true_negatives), \n",
        "                                                'false_positives = {}'.format(false_positives),\n",
        "                                                'false_negatives = {}'.format(false_negatives),\n",
        "                                                'F_1 measure = {}'.format(F_1),\n",
        "                                                'Accuracy = {}'.format(accuracy),\n",
        "                                                'Precision = {}'.format(precision),\n",
        "                                                'Recall = {}'.format(recall), '#'*40], fmt='%s')\n",
        "  return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNMS8oOtLbXA"
      },
      "source": [
        "def bests(data_set):\n",
        "  k_list = [3, 4, 5, 10, 11, 12, 15, 20, 25, 30, 35, 50, 70, 100]\n",
        "  all = []\n",
        "  for k in k_list:\n",
        "    best_accuracy = []\n",
        "    best_recall = []\n",
        "    best_precision = []\n",
        "    best_Fmeasure = []\n",
        "    all.append(KNN_GDA_params(k, data_set))\n",
        "  best_accuracy = max(all, key=lambda x: x[2])\n",
        "  best_recall = max(all, key=lambda x: x[1])\n",
        "  best_precision = max(all, key=lambda x: x[0])\n",
        "  best_Fmeasure = max(all, key=lambda x: x[3])\n",
        "  best_performance_overall = max(all, key=lambda x: [x[i] for i in range(3)])\n",
        "  # print('best_accuracy {} is recorded for k = {}'.format(best_accuracy[2], best_accuracy[4]))\n",
        "  # print('best_recall {} is recorded for k = {}'.format(best_recall[1], best_recall[4]))\n",
        "  # print('best_precision {} is recorded for k = {}'.format(best_precision[0], best_precision[4]))\n",
        "  # print('best_Fmeasure {} is recorded for k = {}'.format(best_Fmeasure[3], best_Fmeasure[4]))\n",
        "  # print('best overall performance {} is recorded for k = {}'.format(best_performance_overall, best_performance_overall[4]))\n",
        "  if data_set[0][20] == ds1_test[0][20]:\n",
        "    np.savetxt(\"#3_b KNN-GDA bests.txt\", ['KNN_GDA parameters for all k in the \\n list = {} \\n are \\n {}'.format(k_list, all),\n",
        "                                          'list of all parameters is \\n {}'.format(all),\n",
        "                                          'best_accuracy {} is recorded for k = {}'.format(best_accuracy[2], best_accuracy[4]),\n",
        "                                          'best_recall {} is recorded for k = {}'.format(best_recall[1], best_recall[4]), \n",
        "                                          'best_precision {} is recorded for k = {}'.format(best_precision[0], best_precision[4]),\n",
        "                                          'best_Fmeasure {} is recorded for k = {}\\n'.format(best_Fmeasure[3], best_Fmeasure[4]),\n",
        "                                          'best overall performance {} is recorded for k = {}'.format(best_performance_overall, \n",
        "                                                                                                      best_performance_overall[4]),\n",
        "                                          '#'*40],fmt='%s')\n",
        "  else:\n",
        "    np.savetxt(\"#5_3 KNN-GDA D2 bests.txt\", ['KNN_GDA parameters for all k in the \\n list = {} \\n are \\n {}'.format(k_list, all),\n",
        "                                             'list of all parameters is \\n {}'.format(all),\n",
        "                                             'best_accuracy {} is recorded for k = {}'.format(best_accuracy[2], best_accuracy[4]),\n",
        "                                             'best_recall {} is recorded for k = {}'.format(best_recall[1], best_recall[4]), \n",
        "                                             'best_precision {} is recorded for k = {}'.format(best_precision[0], best_precision[4]),\n",
        "                                             'best_Fmeasure {} is recorded for k = {}\\n'.format(best_Fmeasure[3], best_Fmeasure[4]),\n",
        "                                             'best overall performance {} is recorded for k = {}'.format(best_performance_overall, \n",
        "                                                                                                         best_performance_overall[4]),\n",
        "                                             '#'*40],fmt='%s')\n",
        "  return all \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrQTAfkj5DmH"
      },
      "source": [
        "bests(ds1_test)\n",
        "# print(all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEwS94We98kG"
      },
      "source": [
        "# # visualization\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "\n",
        "# lables = ['precision', 'recall', 'accuracy', 'F_1', 'k']\n",
        "# x = [3, 4, 5, 10, 11, 12, 15, 20, 25, 30, 35, 50, 70, 100]\n",
        "# # l_list = all\n",
        "# l_list = [[0.7897435897435897, 0.77, 0.7825, 0.7797468354430381, 3],\n",
        "#           [0.8185185185185185, 0.5525, 0.715, 0.6597014925373134, 4],\n",
        "#           [0.7240506329113924, 0.715, 0.72125, 0.7194968553459119, 5],\n",
        "#           [0.694006309148265, 0.55, 0.65375, 0.6136680613668062, 10],\n",
        "#           [0.6317073170731707, 0.6475, 0.635, 0.6395061728395062, 11],\n",
        "#           [0.6676557863501483, 0.5625, 0.64125, 0.6105834464043418, 12],\n",
        "#           [0.6428571428571429, 0.675, 0.65, 0.6585365853658537, 15],\n",
        "#           [0.6556473829201102, 0.595, 0.64125, 0.6238532110091742, 20],\n",
        "#           [0.6153846153846154, 0.64, 0.62, 0.6274509803921569, 25],\n",
        "#           [0.6297297297297297, 0.5825, 0.62, 0.6051948051948052, 30],\n",
        "#           [0.616822429906542, 0.66, 0.625, 0.6376811594202898, 35],\n",
        "#           [0.6120218579234973, 0.56, 0.6025, 0.5848563968668408, 50],\n",
        "#           [0.5882352941176471, 0.55, 0.5825, 0.5684754521963825, 70],\n",
        "#           [0.5892351274787535, 0.52, 0.57875, 0.5524568393094289, 100]]\n",
        "\n",
        "# for i in [x for x in range(len(l_list[0]))]:\n",
        "#     plt.plot(x,[pt[i] for pt in l_list],label = '{}'.format(lables[i]))\n",
        "# print('parameters performance with respect to the k')\n",
        "# plt.legend()\n",
        "# plt.axis([3,60,0.4, 0.85])\n",
        "# plt.gcf().set_size_inches(15, 8)\n",
        "# plt.xlabel(\"k\")\n",
        "# plt.show()\n",
        "\n",
        "# # for i in range(len(l_list[0])):\n",
        "# plt.plot(x,[pt[3] for pt in l_list],label = '%s'%lables[3])\n",
        "# plt.gcf().set_size_inches(15, 8)\n",
        "# plt.legend()\n",
        "# plt.axis([3,60,0.45, 0.8])\n",
        "# plt.xlabel(\"k\")\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XVXWC95XSGf"
      },
      "source": [
        "> **4.** Now instead of having a single multivariate Gaussian distribution per class, each class\n",
        "is going to be generated by a mixture of $3$ Gaussians. For each class, we’ll define\n",
        "$3$ Gaussians, with the first Gaussian of the first class sharing the covariance matrix\n",
        "with the first Gaussian of the second class and so on. For both the classes, fix the\n",
        "mixture probability as $(0.1,0.42,0.48)$ i.e. the sample has arisen from first Gaussian with\n",
        "probability $0.1$, second with probability $0.42$ and so on. Mean for three Gaussians in the\n",
        "positive class are given as $DS2-c1-m1$, $DS2-c1-m2, DS2-c1-m3$. Mean for three Gaussians\n",
        "in the negative class are gives as $DS2-c2-m1$, $DS2-c2-m2$, $DS2-c2-m3$. Corresponding $3$\n",
        "covariance matrices are given as $DS2-cov-1$, $DS2-cov-2$ and $DS2-cov-3$. Now sample\n",
        "from this distribution and generate the dataset similar to question $1$. Call this dataset\n",
        "as $DS2$, and submit it with your code. Follow the instructions from Assignment $1$ for\n",
        "data submission format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQGp2hUX3Y0X"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "data_path = '/content'\n",
        "\n",
        "ds2_c1_m1 = np.loadtxt(data_path + \"/DS2_c1_m1.txt\", delimiter = ',', usecols=range(20))\n",
        "ds2_c1_m2 = np.loadtxt(data_path + \"/DS2_c1_m2.txt\", delimiter = ',', usecols=range(20))\n",
        "ds2_c1_m3 = np.loadtxt(data_path + \"/DS2_c1_m3.txt\", delimiter = ',', usecols=range(20))\n",
        "\n",
        "ds2_c2_m1 = np.loadtxt(data_path + \"/DS2_c2_m1.txt\", delimiter = ',', usecols=range(20))\n",
        "ds2_c2_m2 = np.loadtxt(data_path + \"/DS2_c2_m2.txt\", delimiter = ',', usecols=range(20))\n",
        "ds2_c2_m3 = np.loadtxt(data_path + \"/DS2_c2_m3.txt\", delimiter = ',', usecols=range(20))\n",
        "\n",
        "ds2_cov1 = np.loadtxt(data_path + \"/DS2_Cov1.txt\", delimiter = ',', usecols= range(20))\n",
        "ds2_cov2 = np.loadtxt(data_path + \"/DS2_Cov2.txt\", delimiter = ',', usecols= range(20))\n",
        "ds2_cov3 = np.loadtxt(data_path + \"/DS2_Cov3.txt\", delimiter = ',', usecols= range(20))\n",
        "\n",
        "# plt.plot(ds2_cov1)\n",
        "# plt.title('ds2_cov1')\n",
        "# fig = plt.gcf()\n",
        "# fig.set_size_inches(10, 6)\n",
        "# plt.show()\n",
        "\n",
        "# similar to the question #1\n",
        "Probs_raisen = [0.10, 0.42, 0.48]\n",
        "sample_norm = 2000\n",
        "np.random.seed(1)\n",
        "class_plus = []\n",
        "class_minus = []\n",
        "for i in range(2000):\n",
        "  by_chance = np.random.random()\n",
        "  if (by_chance <= 0.10):\n",
        "    class_plus.append(np.random.multivariate_normal(ds2_c1_m1, ds2_cov1))\n",
        "  elif (by_chance < 0.52):\n",
        "    class_plus.append(np.random.multivariate_normal(ds2_c1_m2, ds2_cov2))\n",
        "  else:\n",
        "    class_plus.append(np.random.multivariate_normal(ds2_c1_m3, ds2_cov3))\n",
        "\n",
        "for j in range(2000):\n",
        "  by_chance = np.random.random()\n",
        "  if (by_chance <= 0.10):\n",
        "    class_minus.append(np.random.multivariate_normal(ds2_c2_m1, ds2_cov1))\n",
        "  elif (by_chance < 0.52):\n",
        "    class_minus.append(np.random.multivariate_normal(ds2_c1_m2, ds2_cov2))\n",
        "  else:\n",
        "    class_minus.append(np.random.multivariate_normal(ds2_c1_m3, ds2_cov3))\n",
        "\n",
        "\n",
        "class_minus = np.insert(class_minus, 20, 0, axis = 1)\n",
        "class_plus = np.insert(class_plus, 20, 1, axis = 1)\n",
        "\n",
        "all_data = np.concatenate((class_plus, class_minus), axis = 0)\n",
        "np.random.shuffle(all_data)\n",
        "\n",
        "# plt.hist(class_minus, label='negative')\n",
        "# plt.ylim([0,1000])\n",
        "# plt.legend(loc = 'upper right')\n",
        "# plt.show()\n",
        "\n",
        "# plt.hist(class_plus, label='positive')\n",
        "# plt.ylim([0,1000])\n",
        "# plt.legend(loc = 'upper right')\n",
        "# plt.show()\n",
        "\n",
        "ds2_train = np.append(class_minus[800:] , class_plus[800:], axis=0)\n",
        "ds2_valid = np.append(class_minus[400:800] , class_plus[400:800], axis=0)\n",
        "ds2_test = np.append(class_minus[:400], class_plus[:400], axis=0)\n",
        "\n",
        "np.random.shuffle(ds2_train)\n",
        "np.random.shuffle(ds2_valid)\n",
        "np.random.shuffle(ds2_test)\n",
        "\n",
        "DS2 = np.append(np.append(ds2_train, ds2_test, axis=0), ds2_valid, axis=0)\n",
        "\n",
        "# print('train set is a', type(ds2_train), ds2_train.shape, 'like', ds2_train[0:1,0:4], '...')\n",
        "# print('validation set is a', type(ds2_valid), ds2_valid.shape, 'like', ds2_valid[0:1,0:4], '...')\n",
        "# print('test set is a', type(ds2_test), ds2_test.shape, 'like', ds2_test[0:1,0:4], '...')\n",
        "\n",
        "np.savetxt('DS2_train.csv', ds2_train, delimiter=',')\n",
        "np.savetxt('DS2_valid.csv', ds2_valid, delimiter=',')\n",
        "np.savetxt('DS2_test.csv', ds2_test, delimiter=',')\n",
        "np.savetxt('DS2.csv', DS2, delimiter=',')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3QUrJtZXzPK"
      },
      "source": [
        ">**5.** Now perform the experiments in questions $2$ and $3$ again, but now using $DS2$.\n",
        ">> **5.1.** Estimate the parameters of the $GDA$ model using the maximum likelihood ap-\n",
        "proach.\n",
        ">>>**5.1.a.** For $DS1$, report the best fit accuracy, precision, recall and F-measure achieved\n",
        "by the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06L8RBFD0kuZ"
      },
      "source": [
        "minus_num_2 = 0\n",
        "plus_num_2 = 0\n",
        "mu_0_2 = np.zeros(20)\n",
        "mu_1_2= np.zeros(20)\n",
        "s_0_2 = 0\n",
        "s_1_2 = 0\n",
        "n_2 = len(ds2_train)\n",
        "for row in ds2_train:\n",
        "  if row[20] == 0:\n",
        "    minus_num_2 += 1\n",
        "    mu_0_2 += row[:20]\n",
        "  else:\n",
        "    plus_num_2 += 1\n",
        "    mu_1_2 += row[:20]\n",
        "\n",
        "p_0_2 = minus_num_2/n_2\n",
        "p_1_2 = plus_num_2/n_2\n",
        "mu_0_2 /= minus_num_2\n",
        "mu_1_2/= plus_num_2\n",
        "\n",
        "#---------------------------------------------------------\n",
        "\n",
        "def cov_matrix(data_set):\n",
        "  s_0_2 = 0\n",
        "  s_1_2 = 0\n",
        "  n_2 = len(data_set)\n",
        "  for row in data_set:\n",
        "    if row[20]==0:\n",
        "      last_2 = np.array(row[:20])\n",
        "      last_2 -= mu_0_2\n",
        "      last_2 = np.reshape(last_2,(20,1))       \n",
        "      s_0_2 += last_2.dot(last_2.T)\n",
        "\n",
        "  s_0_2  /= minus_num_2\n",
        "  for row in data_set:\n",
        "    if row[20]==1:\n",
        "      last_2 = np.array(row[:20])\n",
        "      last_2 -= mu_1_2\n",
        "      last_2 = np.reshape(last_2,(20,1))    \n",
        "      s_1_2 += last_2.dot(last_2.T)\n",
        "\n",
        "  s_1_2 /= plus_num_2\n",
        "  return p_0_2*s_0_2 + p_1_2*s_1_2\n",
        "#---------------------------------------------------------\n",
        "\n",
        "def gaussian_disc(data_set):\n",
        "  cov_temp = np.linalg.inv(cov_matrix(data_set))\n",
        "  w_1_2 = cov_temp.dot(mu_0_2 - mu_1_2)\n",
        "  w_0_2 = -.5*(mu_0_2.T).dot(cov_temp).dot(mu_0_2) + 0.5*(mu_1_2.T).dot(cov_temp).dot(mu_1_2) + np.log(minus_num_2/plus_num_2)\n",
        "  print(\"w_1_2 =\", '\\n',w_1_2)\n",
        "  print(\"w_0_2 =\", '\\n', w_0_2)\n",
        "  return w_0_2, w_1_2\n",
        "#---------------------------------------------------------\n",
        "\n",
        "def activation(x, b, a):\n",
        "  discriminant = b + a.dot(x)\n",
        "  return 1/(1 + np.exp(-discriminant))\n",
        "#---------------------------------------------------------\n",
        "\n",
        "def GDA_params_2(data_set, b, a):\n",
        "  true_positives_2 = 0\n",
        "  true_negatives_2 = 0\n",
        "  false_positives_2 = 0\n",
        "  false_negatives_2 = 0\n",
        "  for row in data_set:\n",
        "    if row[-1] == 0:\n",
        "      if activation(row[:-1], b, a) >= 0.5:\n",
        "        true_negatives_2 += 1\n",
        "      else:\n",
        "        false_positives_2 += 1\n",
        "    else:\n",
        "      if activation(row[:-1], b, a) < 0.5:\n",
        "        true_positives_2 += 1\n",
        "      else:\n",
        "        false_negatives_2 += 1\n",
        "  # print(tabulate([['true_positives_2 =', true_positives_2], ['false_positives_2 =', false_positives_2],\n",
        "  #                ['true_negatives_2 =', true_negatives_2], ['false_negatives_2 =', false_negatives_2]]))\n",
        "  precision_2 = true_positives_2/(true_positives_2 + false_positives_2)\n",
        "  recall_2 = true_positives_2/(true_positives_2 + false_negatives_2)\n",
        "  accuracy_2 = (true_positives_2 + true_negatives_2)/(true_positives_2 + false_negatives_2 + \n",
        "                                                      true_negatives_2 + false_positives_2)\n",
        "  F_1_2 = 2*precision_2*recall_2/(precision_2 + recall_2)\n",
        "\n",
        "  # print and table setting\n",
        "  # print(tabulate([['Accuracy_2 =', accuracy_2], ['Precision_2 =', precision_2],\n",
        "  #                ['Recall_2 =', recall_2], ['F_1_2 measure =', F_1_2]]))\n",
        "  # matrix_2 = np.array([[true_positives_2, false_positives_2],\n",
        "  #                          [false_negatives_2, true_negatives_2]])\n",
        "  # fig, ax = plt.subplots()\n",
        "  # im = ax.imshow(matrix_2)\n",
        "  # actual_value = [\"Actual Positive\", \"Actual Negative\"]\n",
        "  # predicted_value = [\"predicted Positive\", \"predicted Negative\"]\n",
        "  # ax.set_xticks(np.arange(len(predicted_value)))\n",
        "  # ax.set_yticks(np.arange(len(actual_value)))\n",
        "  # ax.set_xticklabels(predicted_value)\n",
        "  # ax.set_yticklabels(actual_value)\n",
        "  # plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "  # for i in range(len(actual_value)):\n",
        "  #   for j in range(len(predicted_value)):\n",
        "  #     text = ax.text(j, i, matrix_2[i, j],ha=\"center\", va=\"center\", color=\"r\")\n",
        "  # fig.tight_layout()\n",
        "  # fig.show()\n",
        "  np.savetxt(\"#5_1_a DS2 parameters.txt\", ['DS2 other variables are \\n ',\n",
        "                                           'true_positives_2 = {}'.format(true_positives_2),\n",
        "                                            'true_negatives_2 = {}'.format(true_negatives_2), \n",
        "                                            'false_positives_2 = {}'.format(false_positives_2),\n",
        "                                            'false_negatives_2 = {}'.format(false_negatives_2),\n",
        "                                            'F_1_2 measure = {}'.format(F_1_2),\n",
        "                                            'Accuracy_2 = {}'.format(accuracy_2),\n",
        "                                            'Precision_2 = {}'.format(precision_2),\n",
        "                                            'Recall_2 = {}'.format(recall_2)], fmt='%s')\n",
        "\n",
        "\n",
        "w_0_2, w_1_2 = gaussian_disc(ds2_train)\n",
        "#------------------------------------------------------------------------------\n",
        "# parameters for test set\n",
        "\n",
        "GDA_params_2(ds2_test, w_0_2, w_1_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HrDYSBoYSWv"
      },
      "source": [
        ">>>**5.1.b.** Report the coefficients learnt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz14n3nL4HZW"
      },
      "source": [
        "w_0_2, w_1_2 = gaussian_disc(ds2_train)\n",
        "np.savetxt(\"#5_1_b coefficients.txt\", ['coefficients are \\n w_0_2 = {}'.format(w_0_2), 'w_1_2 = {}'.format(w_1_2)], fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VESr6nGzYXrf"
      },
      "source": [
        ">>**5.2.** Does $k-NN$ classifier perform better than $GDA$ or worse? Are there particular\n",
        "values of $k$ which perform better? Why does this happen ?\n",
        "\n",
        ">>**5.3.** Report the best fit accuracy, precision, recall and $f-$measure achieved by this clas-\n",
        "sifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew0oWjjk9QDT"
      },
      "source": [
        "\n",
        "bests(ds2_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGoJSBbK-uTN"
      },
      "source": [
        "# # visualization\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "# lables = ['precision_2', 'recall_2', 'accuracy_2', 'F_1_2', 'k']\n",
        "# x = [3, 4, 5, 10, 11, 12, 15, 20, 25, 30, 35, 50, 70, 100]\n",
        "# # l_list = all\n",
        "# l_list = [[0.7524038461538461, 0.7825, 0.7625, 0.767156862745098, 3],\n",
        "#           [0.8214285714285714, 0.5175, 0.7025, 0.6349693251533742, 4],\n",
        "#           [0.6926829268292682, 0.71, 0.6975, 0.7012345679012345, 5],\n",
        "#           [0.6794425087108014, 0.4875, 0.62875, 0.5676855895196506, 10],\n",
        "#           [0.6085858585858586, 0.6025, 0.6075, 0.6055276381909548, 11],\n",
        "#           [0.6462585034013606, 0.475, 0.6075, 0.547550432276657, 12],\n",
        "#           [0.6122448979591837, 0.6, 0.61, 0.6060606060606062, 15],\n",
        "#           [0.625, 0.5, 0.6, 0.5555555555555556, 20],\n",
        "#           [0.5738498789346247, 0.5925, 0.57625, 0.5830258302583026, 25],\n",
        "#           [0.5816023738872403, 0.49, 0.56875, 0.5318860244233379, 30],\n",
        "#           [0.5564102564102564, 0.5425, 0.555, 0.549367088607595, 35],\n",
        "#           [0.5447154471544715, 0.5025, 0.54125, 0.5227568270481144, 50],\n",
        "#           [0.5135135135135135, 0.5225, 0.51375, 0.5179677819083023, 70],\n",
        "#           [0.5114155251141552, 0.56, 0.5125, 0.5346062052505968, 100]]\n",
        "# for i in [x for x in range(len(l_list[0]))]:\n",
        "#     plt.plot(x,[pt[i] for pt in l_list],label = '{}'.format(lables[i]))\n",
        "# print('parameters performance with respect to the k')\n",
        "# plt.legend()\n",
        "# plt.axis([3,65,0.2, 1])\n",
        "# plt.gcf().set_size_inches(15, 8)\n",
        "# plt.xlabel(\"k\")\n",
        "# plt.show()\n",
        "\n",
        "# # for i in range(len(l_list[0])):\n",
        "# plt.plot(x,[pt[3] for pt in l_list],label = '%s'%lables[3])\n",
        "# plt.gcf().set_size_inches(15, 8)\n",
        "# plt.legend()\n",
        "# plt.axis([3,60,0.3, 1])\n",
        "# plt.xlabel(\"k\")\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsZzbaXzYrTM"
      },
      "source": [
        ">**6.** Comment on any similarities and differences between the performance of both classifiers\n",
        "on datasets DS1 and $DS2$?"
      ]
    }
  ]
}